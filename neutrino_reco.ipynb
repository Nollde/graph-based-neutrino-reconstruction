{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5256a63",
   "metadata": {},
   "source": [
    "# Graph Based Neutrino Reconstruction\n",
    "\n",
    "This jupyter notebook has been created for the [Poster Contribution ID 738 on the Acat Conference 2021](https://indico.cern.ch/event/855454/contributions/4596736/).\n",
    "\n",
    "In it, we want to take a closer look at how to setup and use a graph based neutrino reconstruction.\n",
    "\n",
    "\n",
    "## Physics Primer\n",
    "The central approach of the analytic neutrino reconstruction in semi-leptonic decays is to assume that the unmeasured neutrino and the measured lepton originated in a W boson decay. The mass of the W boson is well know.\n",
    "With the assumption that the transverse momentum of the neutrino equals the missing transverse energy (MET) we can deduce the longitudinal momentum of the neutrino to be:\n",
    "\n",
    "$p_{\\nu,z}^{1,2} = \\frac{k}{p_{l,T}^2}\\left(p_{l,z} \\pm E_l\\,\\sqrt{1-\\underbrace{\\left(\\frac{p_{l,T}\\,p_{\\nu,T}}{k}\\right)^2}_{\\equiv\\,h}}\\right)$\n",
    "\n",
    "\n",
    "Depending on the kinematics of an event, two cases for $h$ are possible:\n",
    "* $0 \\leq h \\leq 1$ (real solution): In this case, the longitudinal component of the neutrino can be calculated analytically\n",
    "* $h > 1$ (complex solution): In this case, the longitudinal component of the neutrino can not be calculated analytically. The usual approach is to vary the transversal component of the neutrino such, that $h = 1$. Infinitely many transverse neutrino momenta fulfill this relation. We want to take the one, that is closest to the MET. This solution is found by an event-based fit.\n",
    "\n",
    "This calculation is exemplary for a computation in a HEP analysis which is challenging to vectorise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce1567",
   "metadata": {},
   "source": [
    "First we need to import the necessary software.\n",
    "Our graph library of choice will be tensorflow.\n",
    "\n",
    "We will use:\n",
    " - `tensorflow` for building the graph\n",
    " - `numpy` to handle data outside of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f7f5a9",
   "metadata": {},
   "source": [
    "Now we will define some basic kinematic operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def calc_vy(vx, lepx, lepy, mc, sign=+1, save=False):\n",
    "    s = (mc ** 2 / 2 * (lepx ** 2 + lepy ** 2) * (2 * lepx * vx + mc ** 2 / 2)) ** 0.5\n",
    "    if save:\n",
    "        s = tf.where(s > 0, s, 0)\n",
    "    return (lepx * lepy * vx + lepy * mc ** 2 / 2 + sign * s) / lepx ** 2\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def shift(vx, vy, metx, mety):\n",
    "    return (metx - vx) ** 2 + (mety - vy) ** 2\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_k(lepx, lepy, vx, vy, mc):\n",
    "    return mc ** 2 / 2 + lepx * vx + lepy * vy\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_pt(px, py):\n",
    "    return (px ** 2 + py ** 2) ** 0.5\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_h(lepx, lepy, metx, mety, mc):\n",
    "    k = get_k(lepx, lepy, metx, mety, mc)\n",
    "    leppt = get_pt(lepx, lepy)\n",
    "    metpt = get_pt(metx, mety)\n",
    "    return (leppt * metpt / k) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d7045",
   "metadata": {},
   "source": [
    "Now we can define the first branch of graph, the real component of the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real solution\n",
    "@tf.function\n",
    "def neutrino_reco_real(lepe, lepx, lepy, lepz, vx, vy, mc):\n",
    "    # standard reconstruction\n",
    "    k = get_k(lepx, lepy, vx, vy, mc)\n",
    "    leppt = get_pt(lepx, lepy)\n",
    "    h = get_h(lepx, lepy, vx, vy, mc)\n",
    "\n",
    "    # positive solution\n",
    "    vzp = k / leppt ** 2 * (lepz + lepe * (1 - h) ** 0.5)\n",
    "    # negative solution\n",
    "    vzn = k / leppt ** 2 * (lepz - lepe * (1 - h) ** 0.5)\n",
    "\n",
    "    vz = tf.where(tf.abs(vzp) <= tf.abs(vzn), vzp, vzn)\n",
    "\n",
    "    return vx, vy, vz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36ded30",
   "metadata": {},
   "source": [
    "Now we can define the second branch of the graph, the complex component of the reconstruction.\n",
    "As described above, this component involves fitting the transerval component (in this case $p_x$) of the MET.\n",
    "\n",
    "All parts which are needed for the fit (optimisers, placeholder, ...) will be part of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082cbd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complex solution\n",
    "@tf.function\n",
    "def vx_constrain(vx, lepx, mc):\n",
    "    inf = tf.constant(np.inf)\n",
    "    constr_val = -(mc ** 2) / (4 * lepx)\n",
    "    return tf.where(\n",
    "        lepx >= 0,\n",
    "        tf.clip_by_value(vx, constr_val, inf),\n",
    "        tf.clip_by_value(vx, -inf, constr_val),\n",
    "    )\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def opt(vx0, lepx, lepy, metx, mety, mc, sign=+1):\n",
    "    vy = calc_vy(vx0, lepx, lepy, mc, sign=sign)\n",
    "    return shift(vx0, vy, metx, mety)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def optimize1(optimizer, vx, metx, mety, lepx, lepy, mc, sign=+1):\n",
    "    # two different optimise functions to use them simultaneaously in one computing graph\n",
    "    batch_size = tf.shape(metx)[0]\n",
    "    for _ in range(100):\n",
    "        with tf.control_dependencies(\n",
    "            [\n",
    "                optimizer.minimize(\n",
    "                    lambda: opt(vx[:batch_size], lepx, lepy, metx, mety, mc, sign=sign),\n",
    "                    var_list=[vx],\n",
    "                )\n",
    "            ]\n",
    "        ):\n",
    "            vx[:batch_size].assign(vx_constrain(vx[:batch_size], lepx, mc))\n",
    "    return vx[:batch_size]\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def optimize2(optimizer, vx, metx, mety, lepx, lepy, mc, sign=+1):\n",
    "    # two different optimise functions to use them simultaneaously in one computing graph\n",
    "    batch_size = tf.shape(metx)[0]\n",
    "    for _ in range(100):\n",
    "        with tf.control_dependencies(\n",
    "            [\n",
    "                optimizer.minimize(\n",
    "                    lambda: opt(vx[:batch_size], lepx, lepy, metx, mety, mc, sign=sign),\n",
    "                    var_list=[vx],\n",
    "                )\n",
    "            ]\n",
    "        ):\n",
    "            vx[:batch_size].assign(vx_constrain(vx[:batch_size], lepx, mc))\n",
    "    return vx[:batch_size]\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def neutrino_reco_complex(lepe, lepx, lepy, lepz, metx, mety, vx1, vx2, opt1, opt2, mc):\n",
    "    # complex solution, fit using tensorflow\n",
    "    vx1 = optimize1(opt1, vx1, metx, mety, lepx, lepy, mc, sign=+1)\n",
    "    vx2 = optimize2(opt2, vx2, metx, mety, lepx, lepy, mc, sign=-1)\n",
    "\n",
    "    # catch failed optimizations\n",
    "    constr_val = -(mc ** 2) / (4 * lepx)\n",
    "    vx1 = tf.where(tf.math.is_nan(vx1), constr_val, vx1)\n",
    "    vx2 = tf.where(tf.math.is_nan(vx2), constr_val, vx2)\n",
    "\n",
    "    # reconstruct y component\n",
    "    vy1 = calc_vy(vx1, lepx, lepy, mc, sign=+1, save=True)\n",
    "    vy2 = calc_vy(vx2, lepx, lepy, mc, sign=-1, save=True)\n",
    "\n",
    "    # calculate shift between reco and met\n",
    "    diff1 = shift(vx1, vy1, metx, mety)\n",
    "    diff2 = shift(vx2, vy2, metx, mety)\n",
    "\n",
    "    # take smaller shift\n",
    "    vx = tf.where(diff1 <= diff2, vx1, vx2)\n",
    "    vy = tf.where(diff1 <= diff2, vy1, vy2)\n",
    "\n",
    "    # reconstruct pz component\n",
    "    k = get_k(lepx, lepy, vx, vy, mc)\n",
    "    leppt = get_pt(lepx, lepy)\n",
    "    vz = k * lepz / leppt ** 2\n",
    "    return vx, vy, vz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e7fd7",
   "metadata": {},
   "source": [
    "The flow within the graph is guided with conditional operations (`tf.where`). Here, we interleave the real component and the complex component of the reconstruction depending on the kinematics of each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e74b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def neutrino_reco(lepe, lepx, lepy, lepz, metx, mety, vx1, vx2, opt1, opt2, mc):\n",
    "    # include lep mass in mass constrain\n",
    "    lepm = (lepe ** 2 - lepx ** 2 - lepy ** 2 - lepz ** 2) ** 0.5\n",
    "    lepm = tf.where(tf.math.is_nan(lepm), tf.zeros_like(lepm), lepm)\n",
    "    mc = (mc ** 2 - lepm ** 2) ** 0.5\n",
    "\n",
    "    # interleave standard reconstruction (1) and complex solution (2)\n",
    "    vx_real, vy_real, vz_real = neutrino_reco_real(lepe, lepx, lepy, lepz, metx, mety, mc)\n",
    "    vx_complex, vy_complex, vz_complex = neutrino_reco_complex(\n",
    "        lepe, lepx, lepy, lepz, metx, mety, vx1, vx2, opt1, opt2, mc\n",
    "    )\n",
    "    h = get_h(lepx, lepy, metx, mety, mc)\n",
    "    vx = tf.where(h <= 1, vx_real, vx_complex)\n",
    "    vy = tf.where(h <= 1, vy_real, vy_complex)\n",
    "    vz = tf.where(h <= 1, vz_real, vz_complex)\n",
    "\n",
    "    return vx, vy, vz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f9d2e",
   "metadata": {},
   "source": [
    "Finally we wrap up our graph in a `tf.keras` Model layer.\n",
    "This eases the general handling (initialization, ...) of the underlying graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2174dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeutrinoReco(tf.keras.layers.Layer):\n",
    "    def __init__(self, mass_constraint=80.4, optimizer=\"Adam\", batch_size=1000):\n",
    "        super(NeutrinoReco, self).__init__(name=\"\")\n",
    "        self.opt1 = tf.keras.optimizers.get(optimizer)\n",
    "        self.opt2 = tf.keras.optimizers.get(optimizer)\n",
    "\n",
    "        self.mass_constraint = mass_constraint\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.vx1 = self.add_weight(shape=(self.batch_size,), name=\"vx1\")\n",
    "        self.vx2 = self.add_weight(shape=(self.batch_size,), name=\"vx2\")\n",
    "\n",
    "    def reset_optimizer(self, *args, **kwargs):\n",
    "        # reset optimizer to initial values (all zeros)\n",
    "        for var in self.opt1.variables():\n",
    "            var.assign(tf.zeros_like(var))\n",
    "        for var in self.opt2.variables():\n",
    "            var.assign(tf.zeros_like(var))\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=False):\n",
    "        self.reset_optimizer()\n",
    "        lepe, lepx, lepy, lepz, metx, mety = (inputs[:, i] for i in range(6))\n",
    "\n",
    "        with tf.control_dependencies(\n",
    "            [\n",
    "                self.vx1[: tf.shape(metx)[0]].assign(metx),\n",
    "                self.vx2[: tf.shape(metx)[0]].assign(metx),\n",
    "            ]\n",
    "        ):\n",
    "            vx, vy, vz = neutrino_reco(\n",
    "                lepe,\n",
    "                lepx,\n",
    "                lepy,\n",
    "                lepz,\n",
    "                metx,\n",
    "                mety,\n",
    "                self.vx1,\n",
    "                self.vx2,\n",
    "                self.opt1,\n",
    "                self.opt2,\n",
    "                self.mass_constraint,\n",
    "            )\n",
    "        return vx, vy, vz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e1c97",
   "metadata": {},
   "source": [
    "We can now use our Neutrino reconstruction layer to build a `tf.keras` model. This model can be evaluated locally or loaded onto a tensorflow-model-server. It can additionally be saved to disc and is thus very portable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7973eab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inp = tf.keras.layers.Input(shape=(6,))\n",
    "reco = NeutrinoReco(\n",
    "    mass_constraint=80.4,\n",
    "    optimizer=\"Adam\",\n",
    "    batch_size=100,\n",
    ")\n",
    "vx, vy, vz = reco(inp)\n",
    "outp = [\n",
    "    tf.keras.layers.Lambda(lambda x: x, name=n)(t)\n",
    "    for (n, t) in [(\"x\", vx), (\"y\", vy), (\"z\", vz)]\n",
    "]\n",
    "model = tf.keras.models.Model(inputs=inp, outputs=outp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508656f",
   "metadata": {},
   "source": [
    "We will now define an exemplary input event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874acc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input data in the structure [[lepe, lepx, lepy, lepz, metx, mety]]\n",
    "events = np.array([[ 35.  , -34.   ,  -1.,  -6. , -63.  , -72.  ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4789b1",
   "metadata": {},
   "source": [
    "Now we can evaluate it, using the `tf.keras` model we just have built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2829f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nu_x, nu_y, nu_z = model.predict(events, batch_size=100)\n",
    "print(f\"Neutrino: px={nu_x[0]:.2f}, px: {nu_y[0]:.2f}, px: {nu_z[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dad4aa",
   "metadata": {},
   "source": [
    "We have seen that the calculations through the graph have been performed succesfully. However, the execution took quite so time. This time is attributed to the intitial setup of the graph structure.\n",
    "\n",
    "As it has been setup once now, all following executions are much faster: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645fa4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nu_x, nu_y, nu_z = model.predict(events, batch_size=100)\n",
    "print(f\"Neutrino: px={nu_x[0]:.2f}, px: {nu_y[0]}, px: {nu_z[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276b9e2",
   "metadata": {},
   "source": [
    "Great, looks like it is pretty fast right now!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd15e115",
   "metadata": {},
   "source": [
    "This concludes our tutorial for a graph based neutrino reconstruction. Congrats for making it through!\n",
    "\n",
    "Should you have further questions, please contact me at: dennis.noll \\[at\\] rwth-aachen.de"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
